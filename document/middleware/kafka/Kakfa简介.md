Kafka简介

## 什么是事件流？

事件流相当于人体的中枢神经系统。 它是“永远在线”世界的技术基础，在这个世界中，企业越来越多地使用软件定义和自动化，软件用户更多地使用软件。 

从技术上讲，事件流是指从数据库、传感器、移动设备、云服务和软件应用等事件源以事件流的形式实时捕获数据的实践;持久地存储这些事件流以备以后检索;实时和回顾性地操作、处理和响应事件流;以及根据需要将事件流路由到不同的目标技术。  因此，事件流确保了数据的连续流和解释，从而使正确的信息在正确的时间、正确的地点出现。 

## 我们可以使用事件流做什么？

事件流应用于众多行业和组织的各种用例。它的许多例子包括: 

-  实时处理支付和金融交易，如股票交易所、银行和保险。 
-  实时跟踪和监控汽车、卡车、车队和装运，如在物流和汽车工业中 。
-  从物联网设备或其他设备(如工厂和风电场)中持续捕获和分析传感器数据。 
-  收集并立即对客户交互和订单做出反应，例如在零售、酒店和旅游行业以及移动应用程序中。 
- 监测住院病人的情况，预测病情变化，确保在紧急情况下及时治疗。
- 连接、存储和提供公司不同部门产生的数据。
- 作为数据平台、事件驱动架构和微服务的基础。

## Apache Kafka® 的特性

Kafka结合了三个关键功能，因此你可以用一个经过实战测试的解决方案来实现端到端事件流的用例: 

1. 发布(写)和订阅(读)事件流，包括从其他系统连续导入/导出数据。
2. 持久、可靠地存储事件流，只要您愿意。
3. 在事件发生时或事后对事件流进行处理。

所有这些功能都以一种分布式的、高度可伸缩的、弹性的、容错的和安全的方式提供。Kafka可以部署在裸机硬件、虚拟机和容器上，也可以部署在本地和云上。  您可以选择自管理您的Kafka环境和使用由各种供应商提供的完全管理的服务。 

## Kafka的架构

Kafka是一个分布式系统，由服务器和客户端组成，通过高性能的TCP网络协议进行通信。它可以部署在裸机硬件、虚拟机、内置容器以及云环境中。 

> 服务端
>
>  Kafka作为一个由一个或多个服务器组成的集群运行，这些服务器可以跨越多个数据中心或云区域。其中一些服务器形成存储层，称为代理。其他服务器运行Kafka Connect，以持续导入和导出数据作为事件流，从而将Kafka与您现有的系统(如关系数据库以及其他Kafka集群)集成在一起。为了让您实现关键任务用例，Kafka集群具有高度的可伸缩性和容错能力:如果它的任何一台服务器出现故障，其他服务器将接管它们的工作，以确保在没有任何数据丢失的情况下继续运行。 

> 客户端
>
>  它们允许您编写分布式应用程序和微服务，这些应用程序和微服务可以并行地、大规模地、以容错的方式读写和处理事件流，即使在出现网络问题或机器故障的情况下也是如此。Kafka附带了一些这样的客户端，这些客户端由Kafka社区提供的几十个客户端来增强:客户端可用于Java和Scala，包括更高级的Kafka流库、for Go、Python、C/ c++和许多其他编程语言以及REST api。 

## 关键概念和术语

 一个事件记录了在世界上或在你的生意中“发生了某事”的事实。它在文档中也称为记录或消息。当您向Kafka读取或写入数据时，您将以事件的形式执行此操作。从概念上讲，事件有键、值、时间戳和可选的元数据头。下面是一个例子: 

- 事件的KEY：“ Alice ”
- 事件的VALUE：“ Made a payment of $200 to Bob ”
- 事件发生时间：“ Jun. 25, 2020 at 2:06 p.m. ”

 **Producers**是那些向Kafka发布(写)事件的客户端应用程序， **consumers**是那些订阅(读和处理)这些事件的应用程序。  在Kafka中，生产者和消费者是完全解耦的，互不可知的，这是实现Kafka的高可伸缩性的关键设计元素。  例如，生产者从来不需要等待消费者。Kafka提供了各种保证，比如一次处理事件的能力。 

 事件被组织并长期存储在 **topics** 中。非常简单，主题类似于文件系统中的文件夹，事件是该文件夹中的文件。一个示例主题名称可以是“payments”。Kafka中的主题总是多生产者和多订阅者:一个主题可以有0个、1个或多个向其写入事件的生产者，也可以有0个、1个或多个订阅这些事件的消费者。 可以根据需要读取主题中的事件——与传统消息传递系统不同，事件在使用后不会删除。相反，您可以通过每个主题的配置设置来定义Kafka应该保留多长时间的事件，在此之后旧的事件将被丢弃。Kafka的性能在数据大小方面是有效不变的，所以长时间存储数据是完美的。  

 主题是分区的，这意味着一个主题分散在位于不同Kafka代理上的许多“桶”上。  这种数据的分布式放置对于可伸缩性非常重要，因为它允许客户端应用程序同时从多个代理读取和写入数据。  当新事件发布到主题时，它实际上被附加到主题的一个分区。具有相同事件键的事件(例如，客户ID或车辆ID)被写入相同的分区，Kafka保证给定主题分区的任何消费者都将始终按照写入时完全相同的顺序读取该分区的事件。 

  ![img](http://kafka.apache.org/images/streams-and-tables-p1_p4.png) 

>  说明
>
>  这个示例主题有四个分区P1-P4。两个不同的生产者客户端通过网络将事件写到主题的分区，从而彼此独立地将新事件发布到主题。  具有相同键(图中由其颜色表示)的事件被写入到相同的分区。注意，如果合适，两个生产者可以写入相同的分区。 

让你的数据容错和可用性,每一个主题可以被复制,甚至跨geo-regions或数据中心,这样总有多个经纪人有一份数据以防出错,你想做代理维护,等等。一个常见的生产设置是复制因子为3，也就是说，您的数据总是有三份副本。此复制在主题分区级别上执行。 

这篇引语应该足以作为介绍。如果您感兴趣的话，文档的设计部分详细解释了Kafka的各种概念。 

## Kafka APIS

 除了用于管理和管理任务的命令行工具，Kafka还有五个针对Java和Scala的核心api: 

- 用于管理和检查主题、代理和其他Kafka对象的管理API。 
- 用于向一个或多个Kafka主题发布(写)事件流的生产者API。 
- 消费者API用于订阅(读取)一个或多个主题并处理为它们生成的事件流。
-  Kafka Streams API用于实现流处理应用程序和微服务。它提供了处理事件流的高级功能，包括转换、有状态操作(如聚合和连接)、窗口、基于事件时间的处理等等。从一个或多个主题读取输入，以便生成对一个或多个主题的输出，有效地将输入流转换为输出流。 
-  Kafka Connect API用于构建和运行可重用的数据导入/导出连接器，这些连接器使用(读)或生成(写)来自外部系统和应用程序的事件流，以便它们能够与Kafka集成。例如，连接到关系数据库(如PostgreSQL)的连接器可能会捕获对一组表的每次更改。但是，在实践中，您通常不需要实现自己的连接器，因为Kafka社区已经提供了数百个随时可用的连接器。  